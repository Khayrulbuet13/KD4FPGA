{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from LymphoMNIST.LymphoMNIST import LymphoMNIST\n",
    "from torchvision import transforms\n",
    "from student_qt import FilteredLymphoMNIST, get_dataloaders  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyperparameters\n",
    "params = {\n",
    "    'batch_size': 16,\n",
    "    'im_size': 48,  # Resize dimension used during training\n",
    "    'model_checkpoint': \"../checkpoint/Final_models/KD_13 October 00:13_resnet50_qt-1channel-imsize-120-48.pt\"  # Path to the saved model\n",
    "}\n",
    "\n",
    "BIGGER = 48 # 64 for resnet50 and 48 for tiny model\n",
    "\n",
    "import torchvision.transforms as T\n",
    "transform_student = T.Compose([\n",
    "    T.Resize((BIGGER, BIGGER)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.4819], [0.1484]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists. Skipping download.\n",
      "Dataset already exists. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize datasets\n",
    "labels_to_keep = [0, 1]\n",
    "original_train_ds = LymphoMNIST(root='../dataset', train=True, download=True, transform=transform_student, num_classes=3)\n",
    "original_test_ds = LymphoMNIST(root='../dataset', train=False, download=True, transform=transform_student, num_classes=3)\n",
    "\n",
    "# Filter datasets\n",
    "train_ds = FilteredLymphoMNIST(original_train_ds, labels_to_keep)\n",
    "test_ds = FilteredLymphoMNIST(original_test_ds, labels_to_keep)\n",
    "\n",
    "# Get dataloaders\n",
    "train_dl, val_dl, test_dl = get_dataloaders(train_ds, test_ds, batch_size=params['batch_size'], num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, target in dataloader:\n",
    "            image, target = image.to(device), target.to(device)\n",
    "            outputs = model(image)\n",
    "            output = (torch.max(outputs, 1)[1]).data.cpu().numpy()\n",
    "            y_pred.extend(output)  # Save Prediction\n",
    "            target = target.data.cpu().numpy()\n",
    "            y_true.extend(target)  # Save target\n",
    "\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = models.resnet18()\n",
    "model.conv1 = nn.Conv2d(1, model.conv1.out_channels, kernel_size=model.conv1.kernel_size, stride=model.conv1.stride, padding=model.conv1.padding, bias=False)\n",
    "model.fc = nn.Linear(model.fc.in_features, len(labels_to_keep))\n",
    "\n",
    "# Load saved weights\n",
    "# model.load_state_dict(torch.load('checkpoint/KD_10 October 16:37_resnet50_resnet18-1channel-timm.pt', map_location=device))\n",
    "model.load_state_dict(torch.load('../checkpoint/Final_models/KD_10 October 16:40_resnet50_resnet18-1channel-worked.pt', map_location=device))\n",
    "model = model.to(device)\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(loader, model, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (1, 64, 64)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print accuracies\n",
    "train_acc = calculate_accuracy(train_dl, model, device)\n",
    "print(f'Train Accuracy: {train_acc:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc = calculate_accuracy(val_dl, model, device)\n",
    "print(f'Validation Accuracy: {val_acc:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = calculate_accuracy(test_dl, model, device)\n",
    "print(f'Test Accuracy: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score\n",
    "\n",
    "def get_metrics(y_true, y_pred):\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    auroc = roc_auc_score(y_true, y_pred, average='weighted', multi_class='ovr')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    return precision, recall, f1, auroc, accuracy\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "y_true, y_pred = evaluate_model(model, test_dl, device)\n",
    "\n",
    "# Get the metrics\n",
    "precision, recall, f1, auroc, accuracy = get_metrics(y_true, y_pred)\n",
    "\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "print(f'AUROC: {auroc:.2f}')\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Hyperparameters\n",
    "params = {\n",
    "    'batch_size': 16,  # Standard batch size\n",
    "    'im_size': 64,     # Resize dimension used during training\n",
    "    'num_warmup_batches': 5,  # Number of warmup batches\n",
    "    'num_batches': 100,  # Number of batches to measure (should cover 1000 images)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "# Function to calculate inference speed\n",
    "def calculate_inference_speed(loader, model, device, num_batches, warmup_batches):\n",
    "    model.eval()\n",
    "    total_time = 0.0\n",
    "    images_processed = 0\n",
    "    \n",
    "    # Warm-up loop\n",
    "    with torch.no_grad():\n",
    "        for i, (images, _) in enumerate(loader):\n",
    "            if i >= warmup_batches:\n",
    "                break\n",
    "            images = images.to(device)\n",
    "            _ = model(images)\n",
    "\n",
    "    # Timed inference loop\n",
    "    with torch.no_grad():\n",
    "        for i, (images, _) in enumerate(loader):\n",
    "            if i >= num_batches:\n",
    "                break\n",
    "            images = images.to(device)\n",
    "\n",
    "            start_time = time.time()  # Start timing\n",
    "            _ = model(images)\n",
    "            end_time = time.time()  # End timing\n",
    "\n",
    "            # Update total time and images processed\n",
    "            total_time += (end_time - start_time)\n",
    "            images_processed += images.size(0)\n",
    "\n",
    "    avg_inference_time_per_image = total_time / images_processed\n",
    "    images_per_second = 1.0 / avg_inference_time_per_image\n",
    "    return avg_inference_time_per_image, images_per_second\n",
    "\n",
    "# Run the inference test for 50 iterations and collect the results\n",
    "inference_times = []\n",
    "inference_speeds = []\n",
    "\n",
    "for _ in range(50):\n",
    "    avg_time, throughput = calculate_inference_speed(test_dl, model, device, params['num_batches'], params['num_warmup_batches'])\n",
    "    inference_times.append(avg_time)\n",
    "    inference_speeds.append(throughput)\n",
    "\n",
    "# Calculate the average and standard deviation of inference times and speeds\n",
    "mean_time = np.mean(inference_times)\n",
    "std_time = np.std(inference_times)\n",
    "mean_speed = np.mean(inference_speeds)\n",
    "std_speed = np.std(inference_speeds)\n",
    "\n",
    "print(f'Average Inference Time per Image (over 50 runs): {mean_time:.6f} seconds ± {std_time:.6f}')\n",
    "print(f'Average Inference Speed (over 50 runs): {mean_speed:.2f} images/second ± {std_speed:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Inference Time per Image (over 50 runs): 0.000104 seconds ± 0.000005\n",
    "Average Inference Speed (over 50 runs): 9640.56 images/second ± 407.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example usage:\n",
    "y_true, y_pred = evaluate_model(model, test_dl, device)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "accuracy = np.trace(cm) / np.sum(cm)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "font_size=50\n",
    "# font = {'family' : 'Arial', 'size'   : font_size}\n",
    "font = {'size'   : font_size}\n",
    "plt.rc('font', **font)\n",
    "# plt.rc('text', usetex=True)\n",
    "plt.rcParams['axes.linewidth'] = 1.50\n",
    "\n",
    "# Define tick labels\n",
    "labels = [\"B Cell\", \"T4 Cell\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,7), dpi= 300)\n",
    "\n",
    "original_cmap = plt.cm.get_cmap('rocket')\n",
    "# create new colormap using the top 40%\n",
    "new_cmap = plt.cm.colors.ListedColormap(original_cmap(np.linspace(0.7, 1, 256)))\n",
    "\n",
    "\n",
    "ax = sns.heatmap(cm, annot=True, fmt=\"d\", cmap=new_cmap, xticklabels=labels, yticklabels=labels)\n",
    "# Set tick parameters\n",
    "ax.tick_params(axis='both', length=5, width=0.0, color= 'gray', direction='in')\n",
    "\n",
    "\n",
    "image_name = \"res18_Confusion_test\"\n",
    "plt.savefig(image_name+ '.svg', format='svg', dpi=1200, bbox_inches='tight')\n",
    "plt.savefig(image_name+ '.png', format='png', dpi=1200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage:\n",
    "y_true, y_pred = evaluate_model(model, val_dl, device)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "accuracy = np.trace(cm) / np.sum(cm)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "font_size=50\n",
    "# font = {'family' : 'Arial', 'size'   : font_size}\n",
    "font = {'size'   : font_size}\n",
    "plt.rc('font', **font)\n",
    "# plt.rc('text', usetex=True)\n",
    "plt.rcParams['axes.linewidth'] = 1.50\n",
    "\n",
    "# Define tick labels\n",
    "labels = [\"B Cell\", \"T4 Cell\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,7), dpi= 300)\n",
    "\n",
    "original_cmap = plt.cm.get_cmap('rocket')\n",
    "# create new colormap using the top 40%\n",
    "new_cmap = plt.cm.colors.ListedColormap(original_cmap(np.linspace(0.7, 1, 256)))\n",
    "\n",
    "\n",
    "ax = sns.heatmap(cm, annot=True, fmt=\"d\", cmap=new_cmap, xticklabels=labels, yticklabels=labels)\n",
    "# Set tick parameters\n",
    "ax.tick_params(axis='both', length=5, width=0.0, color= 'gray', direction='in')\n",
    "\n",
    "\n",
    "image_name = \"res18_Confusion_val\"\n",
    "plt.savefig(image_name+ '.svg', format='svg', dpi=1200, bbox_inches='tight')\n",
    "plt.savefig(image_name+ '.png', format='png', dpi=1200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiny model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "class QuantizedCNN(nn.Module):\n",
    "    def __init__(self, num_classes=2, input_size=(1, 28, 28)):\n",
    "        super(QuantizedCNN, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, *input_size)\n",
    "            dummy_output = self.features(dummy_input)\n",
    "            num_ftrs = dummy_output.numel() // dummy_output.size(0)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_ftrs, num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "# Load saved weights\n",
    "model = QuantizedCNN(num_classes=2, input_size=(1, BIGGER, BIGGER)).to(device)\n",
    "\n",
    "# model.load_state_dict(torch.load('checkpoint/KD_10 October 16:38_resnet50_qt-1channel-worked.pt', map_location=device))\n",
    "model.load_state_dict(torch.load(params['model_checkpoint'], map_location=device))\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(loader, model, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (1, 48, 48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 90.83%\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print accuracies\n",
    "train_acc = calculate_accuracy(train_dl, model, device)\n",
    "print(f'Train Accuracy: {train_acc:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 89.73%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "val_acc = calculate_accuracy(val_dl, model, device)\n",
    "print(f'Validation Accuracy: {val_acc:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = calculate_accuracy(test_dl, model, device)\n",
    "print(f'Test Accuracy: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.90\n",
      "Recall: 0.89\n",
      "F1 Score: 0.89\n",
      "AUROC: 0.90\n",
      "Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score\n",
    "\n",
    "def get_metrics(y_true, y_pred):\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    auroc = roc_auc_score(y_true, y_pred, average='weighted', multi_class='ovr')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    return precision, recall, f1, auroc, accuracy\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "y_true, y_pred = evaluate_model(model, test_dl, device)\n",
    "\n",
    "# Get the metrics\n",
    "precision, recall, f1, auroc, accuracy = get_metrics(y_true, y_pred)\n",
    "\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "print(f'AUROC: {auroc:.2f}')\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Hyperparameters\n",
    "params = {\n",
    "    'batch_size': 16,  # Standard batch size\n",
    "    'im_size': 48,     # Resize dimension used during training\n",
    "    'num_warmup_batches': 5,  # Number of warmup batches\n",
    "    'num_batches': 100,  # Number of batches to measure (should cover 1000 images)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "# Function to calculate inference speed\n",
    "def calculate_inference_speed(loader, model, device, num_batches, warmup_batches):\n",
    "    model.eval()\n",
    "    total_time = 0.0\n",
    "    images_processed = 0\n",
    "    \n",
    "    # Warm-up loop\n",
    "    with torch.no_grad():\n",
    "        for i, (images, _) in enumerate(loader):\n",
    "            if i >= warmup_batches:\n",
    "                break\n",
    "            images = images.to(device)\n",
    "            _ = model(images)\n",
    "\n",
    "    # Timed inference loop\n",
    "    with torch.no_grad():\n",
    "        for i, (images, _) in enumerate(loader):\n",
    "            if i >= num_batches:\n",
    "                break\n",
    "            images = images.to(device)\n",
    "\n",
    "            start_time = time.time()  # Start timing\n",
    "            _ = model(images)\n",
    "            end_time = time.time()  # End timing\n",
    "\n",
    "            # Update total time and images processed\n",
    "            total_time += (end_time - start_time)\n",
    "            images_processed += images.size(0)\n",
    "\n",
    "    avg_inference_time_per_image = total_time / images_processed\n",
    "    images_per_second = 1.0 / avg_inference_time_per_image\n",
    "    return avg_inference_time_per_image, images_per_second\n",
    "\n",
    "# Run the inference test for 50 iterations and collect the results\n",
    "inference_times = []\n",
    "inference_speeds = []\n",
    "\n",
    "for _ in range(50):\n",
    "    avg_time, throughput = calculate_inference_speed(test_dl, model, device, params['num_batches'], params['num_warmup_batches'])\n",
    "    inference_times.append(avg_time)\n",
    "    inference_speeds.append(throughput)\n",
    "\n",
    "# Calculate the average and standard deviation of inference times and speeds\n",
    "mean_time = np.mean(inference_times)\n",
    "std_time = np.std(inference_times)\n",
    "mean_speed = np.mean(inference_speeds)\n",
    "std_speed = np.std(inference_speeds)\n",
    "\n",
    "print(f'Average Inference Time per Image (over 50 runs): {mean_time:.6f} seconds ± {std_time:.6f}')\n",
    "print(f'Average Inference Speed (over 50 runs): {mean_speed:.2f} images/second ± {std_speed:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Inference Time per Image (over 50 runs): 0.000015 seconds ± 0.000001\n",
    "Average Inference Speed (over 50 runs): 66891.07 images/second ± 5215.63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example usage:\n",
    "y_true, y_pred = evaluate_model(model, test_dl, device)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "accuracy = np.trace(cm) / np.sum(cm)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "font_size=50\n",
    "# font = {'family' : 'Arial', 'size'   : font_size}\n",
    "font = {'size'   : font_size}\n",
    "plt.rc('font', **font)\n",
    "# plt.rc('text', usetex=True)\n",
    "plt.rcParams['axes.linewidth'] = 1.50\n",
    "\n",
    "# Define tick labels\n",
    "labels = [\"B Cell\", \"T4 Cell\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,7), dpi= 300)\n",
    "\n",
    "original_cmap = plt.cm.get_cmap('rocket')\n",
    "# create new colormap using the top 40%\n",
    "new_cmap = plt.cm.colors.ListedColormap(original_cmap(np.linspace(0.7, 1, 256)))\n",
    "\n",
    "\n",
    "ax = sns.heatmap(cm, annot=True, fmt=\"d\", cmap=new_cmap, xticklabels=labels, yticklabels=labels)\n",
    "# Set tick parameters\n",
    "ax.tick_params(axis='both', length=5, width=0.0, color= 'gray', direction='in')\n",
    "\n",
    "\n",
    "image_name = \"Tiny_Confusion_test\"\n",
    "plt.savefig(image_name+ '.svg', format='svg', dpi=1200, bbox_inches='tight')\n",
    "plt.savefig(image_name+ '.png', format='png', dpi=1200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage:\n",
    "y_true, y_pred = evaluate_model(model, val_dl, device)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "accuracy = np.trace(cm) / np.sum(cm)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "font_size=50\n",
    "# font = {'family' : 'Arial', 'size'   : font_size}\n",
    "font = {'size'   : font_size}\n",
    "plt.rc('font', **font)\n",
    "# plt.rc('text', usetex=True)\n",
    "plt.rcParams['axes.linewidth'] = 1.50\n",
    "\n",
    "# Define tick labels\n",
    "labels = [\"B Cell\", \"T4 Cell\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,7), dpi= 300)\n",
    "\n",
    "original_cmap = plt.cm.get_cmap('rocket')\n",
    "# create new colormap using the top 40%\n",
    "new_cmap = plt.cm.colors.ListedColormap(original_cmap(np.linspace(0.7, 1, 256)))\n",
    "\n",
    "\n",
    "ax = sns.heatmap(cm, annot=True, fmt=\"d\", cmap=new_cmap, xticklabels=labels, yticklabels=labels)\n",
    "# Set tick parameters\n",
    "ax.tick_params(axis='both', length=5, width=0.0, color= 'gray', direction='in')\n",
    "\n",
    "\n",
    "image_name = \"Tiny_Confusion_val\"\n",
    "plt.savefig(image_name+ '.svg', format='svg', dpi=1200, bbox_inches='tight')\n",
    "plt.savefig(image_name+ '.png', format='png', dpi=1200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# defining hook to access output from intermidiate layer\n",
    "def get_features(name):\n",
    "    def hook(model, input, output):\n",
    "        features[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "# registerning the hook. different layer can be accessed by changing\n",
    "# fc[3] parameter. for details \n",
    "# https://kozodoi.me/python/deep%20learning/pytorch/tutorial/2021/05/27/extracting-features.html\n",
    "\n",
    "# print(model)\n",
    "model.classifier[2].register_forward_hook(get_features('feats'))\n",
    "# cnn.conv1.register_forward_hook(get_features('feats'))\n",
    "\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "FEATS = [] # extracted feats will be saved here\n",
    "# placeholder for batch features\n",
    "features = {}\n",
    "# targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for image, targets in test_dl:\n",
    "        image, targets = image.to(device), targets.to(device)\n",
    "        outputs = model(image)\n",
    "        preds = (torch.max(outputs, 1)[1]).data.cpu().numpy()\n",
    "        # y_pred.extend(output) # Save Prediction\n",
    "        # target = target.data.cpu().numpy()\n",
    "        \n",
    "        y_true.extend(targets.cpu().numpy())\n",
    "        y_pred.extend(preds)\n",
    "        \n",
    "        \n",
    "        # targets.extend(target) # Save target\n",
    "        FEATS.extend((features['feats'].cpu().numpy())) # Save feature\n",
    "        \n",
    "y_pred, y_true = np.array(y_pred).reshape(-1,1), np.array(y_true).reshape(-1,1)\n",
    "FEATS = np.array(FEATS)\n",
    "print(f' Feature extracted with shape: (m, C, H, W) = {np.array(FEATS).shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Load the dataset and perform t-SNE embedding\n",
    "tsne_proj = TSNE(n_components=2, perplexity= 15,n_iter=400).fit_transform(FEATS.reshape(FEATS.shape[0], -1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the t-SNE projection\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(np.concatenate((tsne_proj, y_pred, y_true), axis=1))\n",
    "df.to_csv('feats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('feats.csv')\n",
    "\n",
    "# FEATS = last two colimns\n",
    "tsne_proj = df.iloc[:, -4:-2].values\n",
    "y_pred, y_true = df.iloc[:, -2].values, df.iloc[:, -1].values\n",
    "print(f' TSNE shape: (m, n) = {np.array(tsne_proj).shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "colors2 = ['#1f77b4', '#ff7f0e'] # matplotlib default color cycle\n",
    "font_size=50\n",
    "# font = {'family' : 'Arial', 'size'   : font_size}\n",
    "font = {'size'   : font_size}\n",
    "plt.rc('font', **font)\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rcParams['axes.linewidth'] = 1.50\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,15), dpi= 300)\n",
    "\n",
    "# Rename the ticks\n",
    "plot_labels = ['B Cell', 'T4 Cell']  \n",
    "\n",
    "for lab in range(2):\n",
    "    indices = np.array(y_pred)==lab\n",
    "    indices_flat = indices.flatten()\n",
    "\n",
    "    sc = ax.scatter(tsne_proj[indices_flat,0],tsne_proj[indices_flat,1], s=150, color=colors2[lab],  label = plot_labels[lab], alpha=0.7)\n",
    "\n",
    "\n",
    "# plt.legend(fontsize=35)\n",
    "plt.axis('off')\n",
    "\n",
    "image_name = \"TSNE_visu\"\n",
    "plt.savefig(image_name+ '.svg', format='svg', dpi=1200, bbox_inches='tight')\n",
    "plt.savefig(image_name+ '.png', format='png', dpi=1200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # set the model to evaluation mode\n",
    "\n",
    "# Variable for model predictions and true labels\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "roc_data = {\"tiny_test\":[], 'tiny_val':[]}\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for image, target in test_dl:\n",
    "        image, target = image.to(device), target.to(device)\n",
    "        outputs = model(image)\n",
    "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        # Get the probability of the positive class (class 1)\n",
    "        pos_probs = probs[:, 1]\n",
    "        y_pred.extend(pos_probs.cpu().numpy())  # Save predicted probabilities\n",
    "        target = target.data.cpu().numpy()\n",
    "        y_true.extend(target)  # Save actual labels\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# Compute ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "roc_data['tiny_test'] = [fpr, tpr, roc_auc]\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for image, target in val_dl:\n",
    "        image, target = image.to(device), target.to(device)\n",
    "        outputs = model(image)\n",
    "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        # Get the probability of the positive class (class 1)\n",
    "        pos_probs = probs[:, 1]\n",
    "        y_pred.extend(pos_probs.cpu().numpy())  # Save predicted probabilities\n",
    "        target = target.data.cpu().numpy()\n",
    "        y_true.extend(target)  # Save actual labels\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# Compute ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "roc_data['tiny_val'] = [fpr, tpr, roc_auc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np  \n",
    "\n",
    "# File path for saving the JSON\n",
    "file_path = \"tiny_roc.json\"\n",
    "\n",
    "# Convert numpy arrays to lists\n",
    "roc_data_serializable = {\n",
    "    key: [arr.tolist() if isinstance(arr, np.ndarray) else arr for arr in value]\n",
    "    for key, value in roc_data.items()\n",
    "}\n",
    "\n",
    "# Saving the dictionary to a JSON file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(roc_data_serializable, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "lw = 3  # line width\n",
    "multiplier = 0.9\n",
    "colors3 = ['#2ba77b', '#e9a001', '#2274b2']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,4), dpi= 1200)\n",
    "\n",
    "fpr, tpr, roc_auc = roc_data['test']\n",
    "\n",
    "# fpr, tpr, roc_auc = np.array(fpr)*multiplier, np.array(tpr)*multiplier, roc_auc*multiplier\n",
    "\n",
    "plt.plot(fpr, tpr, '-', color=colors3[0], lw=lw, label='Test area = %0.2f' % roc_auc)\n",
    "\n",
    "fpr, tpr, roc_auc = roc_data['val']\n",
    "# fpr, tpr, roc_auc = np.array(fpr)*multiplier, np.array(tpr)*multiplier, roc_auc*multiplier\n",
    "plt.plot(fpr, tpr, '--', color=colors3[1], lw=lw, label='Val area = %0.2f' % roc_auc)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color=colors3[2], lw=lw, linestyle='--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.01])\n",
    "\n",
    "\n",
    "\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "font_size=20\n",
    "# font = {'family' : 'Arial', 'size'   : font_size}\n",
    "font = {'size'   : font_size}\n",
    "plt.rc('font', **font)\n",
    "# plt.rc('text', usetex=True)\n",
    "plt.rcParams['axes.linewidth'] = 1.50\n",
    "\n",
    "\n",
    "\n",
    "# Set tick parameters\n",
    "ax.tick_params(axis='both', length=5, width=1, color= 'gray', direction='in')\n",
    "\n",
    "# Turn off the top and right spines\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Set the color of the axes\n",
    "ax.spines['bottom'].set_color('gray')\n",
    "ax.spines['left'].set_color('gray')\n",
    "\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver Operating Characteristic example')\n",
    "plt.legend(fontsize=font_size*0.65, loc=\"lower right\")\n",
    "\n",
    "\n",
    "# Modify x and y tick labels\n",
    "xticks = ax.get_xticks()\n",
    "yticks = ax.get_yticks()\n",
    "\n",
    "# Remove the first tick\n",
    "# if len(xticks) > 1:\n",
    "#     ax.set_xticks(xticks[1:])\n",
    "# if len(yticks) > 1:\n",
    "#     ax.set_yticks(yticks[1:])\n",
    "\n",
    "# # plt.show()\n",
    "image_name = \"CNN_ROC\"\n",
    "plt.savefig(image_name+ '.svg', format='svg', dpi=1200, bbox_inches='tight')\n",
    "plt.savefig(image_name+ '.png', format='png', dpi=1200, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the JSON files\n",
    "with open('tiny_roc.json', 'r') as f:\n",
    "    tiny_roc_data = json.load(f)\n",
    "\n",
    "with open('res18_roc.json', 'r') as f:\n",
    "    res18_roc_data = json.load(f)\n",
    "\n",
    "# Extract the data\n",
    "fpr_res18_test, tpr_res18_test, auc_res18_test = res18_roc_data['res18_test']\n",
    "fpr_res18_val, tpr_res18_val, auc_res18_val = res18_roc_data['res18_val']\n",
    "\n",
    "fpr_tiny_test, tpr_tiny_test, auc_tiny_test = tiny_roc_data['tiny_test']\n",
    "fpr_tiny_val, tpr_tiny_val, auc_tiny_val = tiny_roc_data['tiny_val']\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "lw = 3  # line width\n",
    "multiplier = 0.9\n",
    "# colors3 = ['#7bbbe0', '#2274b2', '#818082', '#545253', '#2ba77b']\n",
    "colors3 = ['#7bbbe0', '#2274b2', '#f3df3d', '#e9a001', '#2ba77b']\n",
    " \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,3.5), dpi=1200)\n",
    "\n",
    "# Plot res18 test\n",
    "plt.plot(fpr_res18_test, tpr_res18_test, '-', color=colors3[0], lw=lw, label='S1 Test area = %0.2f' % auc_res18_test)\n",
    "# Plot res18 validation\n",
    "plt.plot(fpr_res18_val, tpr_res18_val, '--', color=colors3[1], lw=lw, label='S1 Val area  = %0.2f' % auc_res18_val)\n",
    "\n",
    "# Plot tiny test\n",
    "plt.plot(fpr_tiny_test, tpr_tiny_test, '-', color=colors3[2], lw=lw, label='S2 Test area = %0.2f' % auc_tiny_test)\n",
    "# Plot tiny validation\n",
    "plt.plot(fpr_tiny_val, tpr_tiny_val, '--', color=colors3[3], lw=lw, label='S2 Val area  = %0.2f' % auc_tiny_val)\n",
    "\n",
    "# Diagonal line\n",
    "plt.plot([0, 1], [0, 1], color=colors3[4], lw=lw, linestyle='--')\n",
    "\n",
    "plt.ylim([0.0, 1.01])\n",
    "\n",
    "font_size = 20\n",
    "font = {'size': font_size}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "# Customize axes\n",
    "ax.tick_params(axis='both', length=5, width=1, color='gray', direction='in')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_color('gray')\n",
    "ax.spines['left'].set_color('gray')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(fontsize=font_size * 0.5, loc=\"lower right\")\n",
    "\n",
    "# Save the plot\n",
    "# # plt.show()\n",
    "image_name = \"Student_ROC\"\n",
    "plt.savefig(image_name+ '.svg', format='svg', dpi=1200, bbox_inches='tight')\n",
    "plt.savefig(image_name+ '.png', format='png', dpi=1200, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the 10 colors\n",
    "colors10 = ['#7bbbe0', '#f3df3d', '#2ba77b', '#2274b2', '#e9a001','#818082', '#545253', '#8d2db1', '#d17aad', '#d4580d']\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot 10 bars with the specified colors\n",
    "for i, color in enumerate(colors10):\n",
    "    ax.bar(i, 1, color=color, label=f'{color}')\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xticks(range(10))\n",
    "ax.set_xticklabels([f'Color {i+1}' for i in range(10)], rotation=45, ha='right')\n",
    "ax.set_title(\"10 Color Bars\")\n",
    "ax.set_yticks([])  # Hide y-axis ticks\n",
    "\n",
    "# Add a legend to display the color codes\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameter size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes, mark_inset\n",
    "\n",
    "colors3 = ['#2ba77b', '#e9a001', '#2274b2']\n",
    "\n",
    "def plot_model_comparison(teacher_params, student1_params, student2_params,\n",
    "                          base_radius=0.5, inset_position=None, zoom_factor=100, save_path=None):\n",
    "\n",
    "    font_size = 10\n",
    "    font = {'size': font_size}\n",
    "    plt.rc('font', **font)\n",
    "    plt.rcParams['axes.linewidth'] = 1.50\n",
    "\n",
    "    # Calculate the multiplying factors based on parameters\n",
    "    total_params = teacher_params + student1_params + student2_params\n",
    "    teacher_factor = teacher_params / total_params\n",
    "    student1_factor = student1_params / total_params\n",
    "    student2_factor = student2_params / total_params\n",
    "\n",
    "    # Normalize radii\n",
    "    teacher_radius = base_radius * teacher_factor\n",
    "    student1_radius = base_radius * student1_factor\n",
    "    student2_radius = base_radius * student2_factor\n",
    "\n",
    "    # Create a figure and a set of subplots\n",
    "    fig, ax = plt.subplots(figsize=(5, 4.5), dpi=1200)\n",
    "\n",
    "    # Determine the bottom baseline for the circles\n",
    "    baseline_y = 0.1 * base_radius  # Margin around the plot\n",
    "\n",
    "    # Calculate positions to minimize white space and ensure visibility of all three circles\n",
    "    distance = 0.1 * base_radius  # Small gap between circles\n",
    "    teacher_center = (teacher_radius + distance, baseline_y + teacher_radius)\n",
    "    student1_center = (teacher_center[0] + teacher_radius + student1_radius + distance,\n",
    "                       baseline_y + student1_radius)\n",
    "    student2_center = (student1_center[0] + student1_radius + student2_radius + distance,\n",
    "                       baseline_y + student2_radius)\n",
    "\n",
    "    # Add circles for teacher and students\n",
    "    teacher_circle = plt.Circle(teacher_center, teacher_radius, edgecolor='none',\n",
    "                                facecolor=colors3[0], label='Teacher', alpha=0.5)\n",
    "    student1_circle = plt.Circle(student1_center, student1_radius, edgecolor='none',\n",
    "                                 facecolor=colors3[1], label='Student 1', alpha=0.5)\n",
    "    student2_circle = plt.Circle(student2_center, student2_radius, edgecolor='none',\n",
    "                                 facecolor=colors3[2], label='Student 2', alpha=0.5)\n",
    "\n",
    "    # Add circles to the main plot\n",
    "    ax.add_artist(teacher_circle)\n",
    "    ax.add_artist(student1_circle)\n",
    "    ax.add_artist(student2_circle)\n",
    "\n",
    "    # Setting the limits of the main plot\n",
    "    max_radius = max(teacher_radius, student1_radius, student2_radius)\n",
    "    ax.set_xlim(0, student2_center[0] + student2_radius + 0.1 * base_radius)\n",
    "    ax.set_ylim(0, baseline_y + 2 * max_radius + 0.1 * base_radius)\n",
    "    ax.set_aspect('equal', 'box')\n",
    "\n",
    "    # Remove axis from the main plot\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Adding legend\n",
    "    # plt.legend([teacher_circle, student1_circle, student2_circle],\n",
    "    #            ['Teacher', 'Student 1', 'Student 2'])\n",
    "\n",
    "    # Create a zoomed inset axes with a border\n",
    "    if inset_position is not None:\n",
    "        # inset_position should be [x0, y0, width, height] in axes coordinates (0 to 1)\n",
    "        axins = zoomed_inset_axes(ax, zoom=zoom_factor, loc='right', borderpad=0,\n",
    "                                  bbox_to_anchor=inset_position,\n",
    "                                  bbox_transform=ax.transAxes)\n",
    "    else:\n",
    "        # Default position if inset_position is not provided\n",
    "        axins = zoomed_inset_axes(ax, zoom=zoom_factor, loc='center right', borderpad=1)\n",
    "\n",
    "    # Add circles to the inset plot\n",
    "    teacher_circle_ins = plt.Circle(teacher_center, teacher_radius, edgecolor='none',\n",
    "                                    facecolor=colors3[0], alpha=0.5)\n",
    "    student1_circle_ins = plt.Circle(student1_center, student1_radius, edgecolor='none',\n",
    "                                     facecolor=colors3[1], alpha=0.5)\n",
    "    student2_circle_ins = plt.Circle(student2_center, student2_radius, edgecolor='none',\n",
    "                                     facecolor=colors3[2], alpha=0.5)\n",
    "\n",
    "    axins.add_patch(teacher_circle_ins)\n",
    "    axins.add_patch(student1_circle_ins)\n",
    "    axins.add_patch(student2_circle_ins)\n",
    "\n",
    "    # Set the limits of the inset plot to focus on the Student 2 circle\n",
    "    x1 = student2_center[0] - 2 * student2_radius\n",
    "    x2 = student2_center[0] + 2 * student2_radius\n",
    "    y1 = student2_center[1] - 2 * student2_radius\n",
    "    y2 = student2_center[1] + 2 * student2_radius\n",
    "\n",
    "    axins.set_xlim(x1, x2)\n",
    "    axins.set_ylim(y1, y2)\n",
    "    axins.set_aspect('equal', 'box')\n",
    "\n",
    "    # Remove tick labels from the inset plot\n",
    "    axins.set_xticks([])\n",
    "    axins.set_yticks([])\n",
    "    axins.set_xticklabels([])\n",
    "    axins.set_yticklabels([])\n",
    "\n",
    "    # Add a border around the inset axes\n",
    "    for spine in axins.spines.values():\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(1)\n",
    "\n",
    "    # Indicate the zoomed area on the main plot\n",
    "    mark_inset(ax, axins, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\")\n",
    "\n",
    "    # Save the figure if a save path is provided\n",
    "    if save_path:\n",
    "        plt.savefig(save_path + '.svg', format='svg', dpi=1200, bbox_inches='tight')\n",
    "        plt.savefig(save_path + '.png', format='png', dpi=1200, bbox_inches='tight')\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "T_pram = 23512130\n",
    "s1_pram = 11171266\n",
    "s2_pram = 5682\n",
    "\n",
    "# Specify the inset position [x0, y0, width, height] in axes coordinates (0 to 1)\n",
    "inset_position = [0.76, 0.1, 0.25, 0.25]  # Adjust these values as needed\n",
    "\n",
    "# Call the function with the desired zoom factor\n",
    "plot_model_comparison(T_pram, s1_pram, s2_pram, inset_position=inset_position, zoom_factor=200, save_path=\"params\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data for inference speed\n",
    "models = ['Teacher', 'Student 1', 'Student 2']\n",
    "inference_speed = [3979.52, 9640.56, 66891.07]  # Images per second\n",
    "inference_speed_std = [114.05, 407.05, 5215.63]  # Standard deviation\n",
    "\n",
    "# Plot settings\n",
    "font_size = 20\n",
    "font = {'size': font_size}\n",
    "plt.rc('font', **font)\n",
    "plt.rcParams['axes.linewidth'] = 1.50\n",
    "\n",
    "# Colors for the bars\n",
    "colors3 = ['#2ba77b', '#e9a001', '#2274b2']\n",
    "\n",
    "# Width of the bars\n",
    "bar_width = 0.6\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(2, 3.1), dpi=100)\n",
    "\n",
    "# Plot the bar chart\n",
    "bars = ax.bar(models, inference_speed, yerr=inference_speed_std, align='center', alpha=0.5, \n",
    "              edgecolor='none', linewidth=0, error_kw={'elinewidth': 0.5}, width=bar_width, capsize=3)\n",
    "\n",
    "# Color each bar\n",
    "for i, bar in enumerate(bars):\n",
    "    bar.set_color(colors3[i])\n",
    "\n",
    "# Customize tick parameters\n",
    "ax.tick_params(axis='both', length=10, width=0.0, color='gray', direction='in')\n",
    "\n",
    "# Set title and adjust y-ticks\n",
    "# ax.title.set_text('Inference Speed (Images/Second)')\n",
    "# plt.yticks(fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylim([0, 80000])  # Adjust the limit for better visibility\n",
    "# Set y-axis to scientific notation\n",
    "ax.ticklabel_format(style='scientific', axis='y', scilimits=(0, 0))\n",
    "\n",
    "# Save the plot\n",
    "image_name = \"./inference_speed\"\n",
    "plt.savefig(image_name + '.svg', format='svg', dpi=1200, bbox_inches='tight')\n",
    "plt.savefig(image_name + '.png', format='png', dpi=1200, bbox_inches='tight')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvsb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
