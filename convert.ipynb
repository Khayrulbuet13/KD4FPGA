{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, ReLU, MaxPooling2D, Flatten, Dropout, Dense, Softmax, Input\n",
    "\n",
    "# Define PyTorch model\n",
    "class QuantizedCNN(nn.Module):\n",
    "    def __init__(self, num_classes=2, input_size=(1, 48, 48)):\n",
    "        super(QuantizedCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        )\n",
    "        num_ftrs = 16 * 10 * 10\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_ftrs, num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Initialize PyTorch model\n",
    "STUDENT_IM_SIZE = 48\n",
    "num_classes = 2\n",
    "pytorch_model = QuantizedCNN(num_classes=num_classes, input_size=(1, STUDENT_IM_SIZE, STUDENT_IM_SIZE))\n",
    "pytorch_model.load_state_dict(torch.load('checkpoint/Final_models/KD_13 October 00:13_resnet50_qt-1channel-imsize-120-48.pt', map_location='cpu'))\n",
    "pytorch_model.eval()\n",
    "\n",
    "# Extract weights from PyTorch model\n",
    "state_dict = pytorch_model.state_dict()\n",
    "conv1_weight = state_dict['features.0.weight'].cpu().numpy()\n",
    "conv1_bias = state_dict['features.0.bias'].cpu().numpy()\n",
    "conv2_weight = state_dict['features.3.weight'].cpu().numpy()\n",
    "conv2_bias = state_dict['features.3.bias'].cpu().numpy()\n",
    "dense_weight = state_dict['classifier.2.weight'].cpu().numpy()\n",
    "dense_bias = state_dict['classifier.2.bias'].cpu().numpy()\n",
    "\n",
    "# Transpose weights for Keras\n",
    "conv1_weight = np.transpose(conv1_weight, (2, 3, 1, 0))\n",
    "conv2_weight = np.transpose(conv2_weight, (2, 3, 1, 0))\n",
    "dense_weight = dense_weight.T\n",
    "\n",
    "from tensorflow.keras.layers import Permute\n",
    "# Define Keras model\n",
    "def create_keras_model(input_shape=(48, 48, 1), num_classes=2):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Conv2D(16, kernel_size=3, strides=1, padding='valid'))\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(Conv2D(16, kernel_size=3, strides=1, padding='valid'))\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(Permute((3, 1, 2)))  # Rearrange axes to (C, H, W)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Softmax())\n",
    "    return model\n",
    "\n",
    "\n",
    "keras_model = create_keras_model(input_shape=(STUDENT_IM_SIZE, STUDENT_IM_SIZE, 1), num_classes=num_classes)\n",
    "print(keras_model.summary())\n",
    "\n",
    "# # Print layer indices and names to confirm\n",
    "# for idx, layer in enumerate(keras_model.layers):\n",
    "#     print(f\"Layer {idx}: {layer.name} ({layer.__class__.__name__})\")\n",
    "\n",
    "# # Assign weights to Keras layers using correct indices\n",
    "# keras_model.layers[0].set_weights([conv1_weight, conv1_bias])  # Conv1\n",
    "# keras_model.layers[3].set_weights([conv2_weight, conv2_bias])  # Conv2\n",
    "# keras_model.layers[8].set_weights([dense_weight, dense_bias])  # Dense\n",
    "\n",
    "\n",
    "# Print layer indices and names to confirm\n",
    "for idx, layer in enumerate(keras_model.layers):\n",
    "    print(f\"Layer {idx}: {layer.name} ({layer.__class__.__name__})\")\n",
    "\n",
    "# Assign weights to the correct layers\n",
    "keras_model.layers[0].set_weights([conv1_weight, conv1_bias])  # Conv1 (Layer 0)\n",
    "keras_model.layers[3].set_weights([conv2_weight, conv2_bias])  # Conv2 (Layer 3)\n",
    "keras_model.layers[-2].set_weights([dense_weight, dense_bias])  # Dense (Layer 9)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Prepare input data\n",
    "input_data = np.random.randn(1, 1, STUDENT_IM_SIZE, STUDENT_IM_SIZE).astype(np.float32)\n",
    "pytorch_input = torch.from_numpy(input_data)\n",
    "keras_input = np.transpose(input_data, (0, 2, 3, 1))  # Convert NCHW to NHWC\n",
    "\n",
    "# Get outputs from both models\n",
    "pytorch_output = pytorch_model(pytorch_input).detach().numpy()\n",
    "keras_output = keras_model.predict(keras_input)\n",
    "\n",
    "# Compare outputs\n",
    "difference = np.abs(pytorch_output - keras_output)\n",
    "print('PyTorch output:', pytorch_output)\n",
    "print('Keras output:', keras_output)\n",
    "print('Max difference:', difference.max())\n",
    "\n",
    "keras_model.save('converted_keras_model_fixed.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantizedCNN(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): Linear(in_features=1600, out_features=2, bias=True)\n",
       "    (3): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, ReLU, MaxPooling2D, Flatten, Dropout, Dense, Softmax, Input\n",
    "\n",
    "# Define PyTorch model\n",
    "class QuantizedCNN(nn.Module):\n",
    "    def __init__(self, num_classes=2, input_size=(1, 48, 48)):\n",
    "        super(QuantizedCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        )\n",
    "        # Dynamically compute the number of features\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, *input_size)\n",
    "            dummy_output = self.features(dummy_input)\n",
    "            num_ftrs = dummy_output.numel() // dummy_output.size(0)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_ftrs, num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Initialize PyTorch model\n",
    "STUDENT_IM_SIZE = 48\n",
    "num_classes = 2\n",
    "pytorch_model = QuantizedCNN(num_classes=num_classes, input_size=(1, STUDENT_IM_SIZE, STUDENT_IM_SIZE))\n",
    "# pytorch_model.load_state_dict(torch.load('checkpoint/Final_models/KD_13 October 00:13_resnet50_qt-1channel-imsize-120-48.pt', map_location='cpu'))\n",
    "pytorch_model.load_state_dict(torch.load('checkpoint/KD_21 October 14:13_resnet50_qt-1channel-no_normalize.pt', map_location='cpu'))\n",
    "pytorch_model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features output shape: C=16, H=10, W=10\n",
      "Layer 0: conv2d (Conv2D)\n",
      "Layer 1: re_lu (ReLU)\n",
      "Layer 2: max_pooling2d (MaxPooling2D)\n",
      "Layer 3: conv2d_1 (Conv2D)\n",
      "Layer 4: re_lu_1 (ReLU)\n",
      "Layer 5: max_pooling2d_1 (MaxPooling2D)\n",
      "Layer 6: flatten (Flatten)\n",
      "Layer 7: dropout (Dropout)\n",
      "Layer 8: dense (Dense)\n",
      "Layer 9: softmax (Softmax)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1729566951.313951  763255 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729566951.315576  763255 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729566951.316931  763255 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729566951.318341  763255 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-21 23:15:51.323223: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch output: [[0. 1.]]\n",
      "Keras output: [[0. 1.]]\n",
      "Max difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Extract weights from PyTorch model\n",
    "state_dict = pytorch_model.state_dict()\n",
    "conv1_weight = state_dict['features.0.weight'].cpu().numpy()\n",
    "conv1_bias = state_dict['features.0.bias'].cpu().numpy()\n",
    "conv2_weight = state_dict['features.3.weight'].cpu().numpy()\n",
    "conv2_bias = state_dict['features.3.bias'].cpu().numpy()\n",
    "dense_weight = state_dict['classifier.2.weight'].cpu().numpy()\n",
    "dense_bias = state_dict['classifier.2.bias'].cpu().numpy()\n",
    "\n",
    "# Transpose weights for Keras Conv2D layers\n",
    "conv1_weight = np.transpose(conv1_weight, (2, 3, 1, 0))\n",
    "conv2_weight = np.transpose(conv2_weight, (2, 3, 1, 0))\n",
    "\n",
    "# Compute the output dimensions after the feature extractor\n",
    "with torch.no_grad():\n",
    "    dummy_input = torch.zeros(1, 1, STUDENT_IM_SIZE, STUDENT_IM_SIZE)\n",
    "    dummy_output = pytorch_model.features(dummy_input)\n",
    "    _, C, H, W = dummy_output.shape\n",
    "print(f\"Features output shape: C={C}, H={H}, W={W}\")\n",
    "\n",
    "# Adjust the Dense layer weights to match Keras flattening order\n",
    "# In PyTorch, the flattening order is (C, H, W)\n",
    "# In Keras, the flattening order is (H, W, C)\n",
    "dense_weight = dense_weight.reshape(num_classes, C, H, W)\n",
    "dense_weight = np.transpose(dense_weight, (0, 2, 3, 1))  # (num_classes, H, W, C)\n",
    "dense_weight = dense_weight.reshape(num_classes, -1)       # Flatten to (num_classes, H*W*C)\n",
    "dense_weight = dense_weight.T                              # Transpose to (H*W*C, num_classes)\n",
    "\n",
    "# Define Keras model without Permute layer\n",
    "def create_keras_model(input_shape=(48, 48, 1), num_classes=2):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Conv2D(16, kernel_size=3, strides=1, padding='valid'))\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(Conv2D(16, kernel_size=3, strides=1, padding='valid'))\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n",
    "    # Removed Permute layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Softmax())\n",
    "    return model\n",
    "\n",
    "keras_model = create_keras_model(input_shape=(STUDENT_IM_SIZE, STUDENT_IM_SIZE, 1), num_classes=num_classes)\n",
    "# Print layer indices and names to confirm\n",
    "for idx, layer in enumerate(keras_model.layers):\n",
    "    print(f\"Layer {idx}: {layer.name} ({layer.__class__.__name__})\")\n",
    "\n",
    "# Assign weights to the correct layers\n",
    "keras_model.layers[0].set_weights([conv1_weight, conv1_bias])  # Conv1 (Layer 1)\n",
    "keras_model.layers[3].set_weights([conv2_weight, conv2_bias])  # Conv2 (Layer 4)\n",
    "keras_model.layers[8].set_weights([dense_weight, dense_bias])   # Dense (Layer 9)\n",
    "\n",
    "# Prepare input data\n",
    "input_data = np.random.randn(1, 1, STUDENT_IM_SIZE, STUDENT_IM_SIZE).astype(np.float32)\n",
    "pytorch_input = torch.from_numpy(input_data)\n",
    "keras_input = np.transpose(input_data, (0, 2, 3, 1))  # Convert NCHW to NHWC\n",
    "\n",
    "# Get outputs from both models\n",
    "pytorch_output = pytorch_model(pytorch_input).detach().numpy()\n",
    "keras_output = keras_model.predict(keras_input)\n",
    "\n",
    "\n",
    "# Compare outputs\n",
    "difference = np.abs(pytorch_output - keras_output)\n",
    "print('PyTorch output:', pytorch_output)\n",
    "print('Keras output:', keras_output)\n",
    "print('Max difference:', difference.max())\n",
    "keras_model.save('converted_keras_model_normalized.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, ReLU, Softmax\n",
    "from tensorflow.keras.models import Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# --- Create and Load Keras Model ---\n",
    "def create_keras_model():\n",
    "    input_layer = Input(shape=(48, 48, 1), name='input_layer')\n",
    "    x = Conv2D(16, (3, 3), padding='valid')(input_layer)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D(pool_size=2, strides=2, padding='valid')(x)\n",
    "    x = Conv2D(16, (3, 3), padding='valid')(x)\n",
    "    x = ReLU()(x)  # Add ReLU here\n",
    "    x = MaxPooling2D(pool_size=2, strides=2, padding='valid')(x)\n",
    "    # x = Permute((3, 1, 2))(x)  # Add Permute layer here\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(2)(x)\n",
    "    output_layer = Softmax()(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "\n",
    "keras_model = create_keras_model()\n",
    "# keras_model.load_weights('converted_keras_model_fixed.h5')\n",
    "keras_model.load_weights('converted_keras_model_fixed.h5')\n",
    "\n",
    "# --- Prepare Input Data for Both Models ---\n",
    "input_shape = (1, 48, 48, 1)  # Adjust this as necessary\n",
    "dummy_input_keras = np.random.rand(*input_shape).astype('float32')\n",
    "\n",
    "# Run the Keras model once to ensure it's fully initialized\n",
    "keras_predictions = keras_model.predict(dummy_input_keras)\n",
    "\n",
    "# Print model summary\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Capture Activations from Keras Model ---\n",
    "flatten_layer_name = 'flatten'  # Confirm this name matches your model summary\n",
    "activation_model_keras = Model(inputs=keras_model.input, outputs=keras_model.get_layer(flatten_layer_name).output)\n",
    "flatten_output_keras = activation_model_keras.predict(dummy_input_keras)\n",
    "print(\"Keras Flatten output shape:\", flatten_output_keras.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "# --- Load and Prepare PyTorch Model ---\n",
    "class QuantizedCNN(nn.Module):\n",
    "    def __init__(self, num_classes=2, input_size=(1, 48, 48)):\n",
    "        super(QuantizedCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, *input_size)\n",
    "            dummy_output = self.features(dummy_input)\n",
    "            num_ftrs = dummy_output.numel() // dummy_output.size(0)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_ftrs, num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "device = 'cpu'\n",
    "pytorch_model = QuantizedCNN(num_classes=2, input_size=(1, 48, 48)).to(device)\n",
    "pytorch_model.load_state_dict(torch.load('checkpoint/Final_models/KD_13 October 00:13_resnet50_qt-1channel-imsize-120-48.pt', map_location=device))\n",
    "pytorch_model.eval()\n",
    "\n",
    "# Use torchsummary to print the model summary, explicitly setting the device\n",
    "# summary(pytorch_model, (1, 48, 48), device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert Keras input to match PyTorch's input format (N, C, H, W)\n",
    "dummy_input_pytorch = torch.from_numpy(dummy_input_keras.transpose(0, 3, 1, 2)).float()\n",
    "\n",
    "# --- Capture Activations from PyTorch Model ---\n",
    "activations = {}\n",
    "\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "# Register hook\n",
    "pytorch_model.classifier[0].register_forward_hook(get_activation('flatten_output'))\n",
    "\n",
    "# Run the PyTorch model\n",
    "with torch.no_grad():\n",
    "    pytorch_predictions = pytorch_model(dummy_input_pytorch)\n",
    "\n",
    "flatten_output_pytorch = activations['flatten_output'].numpy()\n",
    "print(\"PyTorch Flatten output shape:\", flatten_output_pytorch.shape)\n",
    "\n",
    "# Reshape PyTorch output to match Keras convention (N, H, W, C)\n",
    "# flatten_output_pytorch = flatten_output_pytorch.transpose(0, 2, 3, 1)\n",
    "print(\"PyTorch Flatten output shape:\", flatten_output_pytorch.shape)\n",
    "\n",
    "# --- Compare the Activations ---\n",
    "difference = np.abs(flatten_output_pytorch - flatten_output_keras)\n",
    "print(\"Max difference:\", np.max(difference))\n",
    "print(\"Mean difference:\", np.mean(difference))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "import torch\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from LymphoMNIST.LymphoMNIST import LymphoMNIST\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Define Dataset and Helper Functions\n",
    "\n",
    "# %%\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "class FilteredLymphoMNIST(Dataset):\n",
    "    def __init__(self, original_dataset, labels_to_keep):\n",
    "        self.original_dataset = original_dataset\n",
    "        self.indices = [i for i, (_, label) in enumerate(original_dataset) if label in labels_to_keep]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.original_dataset[self.indices[index]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "def get_dataloaders(train_ds, val_ds, batch_size=BATCH_SIZE, **kwargs):\n",
    "    val_size = len(val_ds) // 2\n",
    "    test_size = len(val_ds) - val_size\n",
    "    val_ds, test_ds = random_split(val_ds, [val_size, test_size])\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=batch_size, shuffle=True, **kwargs),\n",
    "        DataLoader(val_ds, batch_size=batch_size, shuffle=False, **kwargs),\n",
    "        DataLoader(test_ds, batch_size=batch_size, shuffle=False, **kwargs),\n",
    "    )\n",
    "    \n",
    "\n",
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(loader, model, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "    \n",
    "\n",
    "# Hyperparameters\n",
    "params = {\n",
    "    'batch_size': 16,\n",
    "    'im_size': 48,  # Resize dimension used during training\n",
    "    'model_checkpoint': \"../checkpoint/Final_models/KD_13 October 00:13_resnet50_qt-1channel-imsize-120-48.pt\"  # Path to the saved model\n",
    "}\n",
    "\n",
    "BIGGER = 48\n",
    "\n",
    "import torchvision.transforms as T\n",
    "transform_student = T.Compose([\n",
    "    T.Resize((BIGGER, BIGGER)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.4819], [0.1484]),\n",
    "])\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Initialize the Dataset\n",
    "\n",
    "# %%\n",
    "# Initialize datasets\n",
    "labels_to_keep = [0, 1]\n",
    "original_train_ds = LymphoMNIST(root='../dataset', train=True, download=True, transform=transform_student, num_classes=3)\n",
    "original_test_ds = LymphoMNIST(root='../dataset', train=False, download=True, transform=transform_student, num_classes=3)\n",
    "\n",
    "# Filter datasets\n",
    "train_ds = FilteredLymphoMNIST(original_train_ds, labels_to_keep)\n",
    "test_ds = FilteredLymphoMNIST(original_test_ds, labels_to_keep)\n",
    "\n",
    "\n",
    "\n",
    "# Get dataloaders\n",
    "train_dl, val_dl, test_dl = get_dataloaders(train_ds, test_ds, batch_size=params['batch_size'], num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to calculate accuracy using Keras model\n",
    "def calculate_accuracy_keras(loader, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loader:\n",
    "        # images: Tensor of shape (batch_size, channels, height, width)\n",
    "        # labels: Tensor of shape (batch_size)\n",
    "        \n",
    "        # Convert images to numpy arrays and reshape to (batch_size, height, width, channels)\n",
    "        images_np = images.numpy()\n",
    "        images_np = images_np.transpose(0, 2, 3, 1)  # Convert from (N, C, H, W) to (N, H, W, C)\n",
    "        \n",
    "        # Perform inference with Keras model\n",
    "        predictions = model.predict(images_np)\n",
    "        \n",
    "        # Get predicted labels\n",
    "        predicted_labels = np.argmax(predictions, axis=1)\n",
    "        labels_np = labels.numpy()\n",
    "        \n",
    "        total += labels_np.shape[0]\n",
    "        correct += (predicted_labels == labels_np).sum()\n",
    "        \n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Calculate and print accuracy on the test dataset\n",
    "test_accuracy = calculate_accuracy_keras(test_dl, keras_model)\n",
    "print(f'Test Accuracy with Keras model: {test_accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvsb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
