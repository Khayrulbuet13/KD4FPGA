{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from teacher_train import val_transform, FilteredLymphoMNIST, get_dataloaders\n",
    "# from teacher_train import WeightedRandomSampler, balanced_weights\n",
    "from LymphoMNIST.LymphoMNIST import LymphoMNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler, Dataset\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class to filter by labels\n",
    "class FilteredLymphoMNIST(Dataset):\n",
    "    def __init__(self, original_dataset, labels_to_keep):\n",
    "        self.original_dataset = original_dataset\n",
    "        self.labels_to_keep = labels_to_keep\n",
    "        self.label_map = {label: i for i, label in enumerate(labels_to_keep)}\n",
    "        self.indices = [i for i, (_, label) in enumerate(original_dataset) if label in labels_to_keep]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        original_index = self.indices[index]\n",
    "        image, label = self.original_dataset[original_index]\n",
    "        return image, self.label_map[label.item()]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "# Function to get dataloaders\n",
    "def get_dataloaders(train_ds, val_ds, split=(0.5, 0.5), batch_size=64, sampler=None, *args, **kwargs):\n",
    "    lengths = [int(len(val_ds) * frac) for frac in split]\n",
    "    lengths[1] += len(val_ds) - sum(lengths)  # Correct split length sum\n",
    "    val_ds, test_ds = torch.utils.data.random_split(val_ds, lengths)\n",
    "\n",
    "    shuffle = False if sampler else True\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=shuffle, sampler=sampler, *args, **kwargs)\n",
    "    val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=False, *args, **kwargs)\n",
    "    test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=False, *args, **kwargs)\n",
    "\n",
    "    return train_dl, val_dl, test_dl\n",
    "\n",
    "# Dataset and data augmentation classes\n",
    "class ConvertToRGB:\n",
    "    def __call__(self, tensor):\n",
    "        if tensor.shape[0] == 1:\n",
    "            tensor = tensor.repeat(3, 1, 1)\n",
    "        return tensor\n",
    "    \n",
    "\n",
    "# # Balanced weights function for weighted sampling\n",
    "# def balanced_weights(dataset, nclasses):\n",
    "#     count = [0] * nclasses\n",
    "#     for _, label in dataset:\n",
    "#         count[label] += 1\n",
    "#     N = float(sum(count))\n",
    "#     weight_per_class = [N / float(count[i]) for i in range(nclasses)]\n",
    "#     return [weight_per_class[label] for _, label in dataset]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our hyperparameters\n",
    "params = {\n",
    "    'lr': 1e-5,\n",
    "    'batch_size': 16,\n",
    "    'epochs': 10000,\n",
    "    'model': \"Teacher_final-3c\",\n",
    "    'im_size': 120,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "im_size = params['im_size']\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((im_size, im_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4819], [0.1484]),\n",
    "    ConvertToRGB()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize dataset\n",
    "original_train_ds = LymphoMNIST(root='../dataset', train=True, download=True, transform=val_transform, num_classes=3)\n",
    "original_test_ds = LymphoMNIST(root='../dataset', train=False, download=True, transform=val_transform, num_classes=3)\n",
    "\n",
    "\n",
    "# Specify labels to keep\n",
    "labels_to_keep = [0, 1] # 0: B, 1: T4, 2: T8\n",
    "\n",
    "# Initialize filtered dataset with labels to keep\n",
    "train_ds = FilteredLymphoMNIST(original_train_ds, labels_to_keep)\n",
    "test_ds= FilteredLymphoMNIST(original_test_ds, labels_to_keep)\n",
    "\n",
    "# weights = balanced_weights(train_ds, len(labels_to_keep))\n",
    "# sampler = WeightedRandomSampler(weights, len(weights))\n",
    "# Create the dataloaders\n",
    "# train_dl, val_dl, test_dl = get_dataloaders(train_ds,\n",
    "#                                             test_ds,\n",
    "#                                             split=(0.5, 0.5),\n",
    "#                                             batch_size=params['batch_size'],\n",
    "#                                             # sampler=sampler,\n",
    "#                                             num_workers=4\n",
    "#                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "\n",
    "def calculate_accuracy(loader, model, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# Load the model\n",
    "model = models.resnet50()\n",
    "model.fc = nn.Linear(model.fc.in_features, len(labels_to_keep))\n",
    "\n",
    "# Load the saved weights and map them to the correct device\n",
    "model.load_state_dict(torch.load(\"../checkpoint/Final_models/Teacher_imsize-120_30 September 22_37.pt\", map_location=device))\n",
    "\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (3, 120, 120))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latency calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator, Tuple, Any\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def calculate_true_latency(\n",
    "    loader: Iterator[Tuple[torch.Tensor, Any]],\n",
    "    model: torch.nn.Module,\n",
    "    device: torch.device,\n",
    "    num_batches: int = 20,\n",
    "    warmup_batches: int = 500,\n",
    "    percentiles: tuple = (50, 90, 95, 99)\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Calculate true model latency using CUDA events and proper synchronization.\n",
    "   \n",
    "    Args:\n",
    "        loader: DataLoader iterator\n",
    "        model: PyTorch model\n",
    "        device: Device to run inference on\n",
    "        num_batches: Number of batches to measure\n",
    "        warmup_batches: Number of warmup batches\n",
    "        percentiles: Tuple of percentiles to calculate\n",
    "       \n",
    "    Returns:\n",
    "        Dictionary containing latency statistics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    latencies = []\n",
    "    batch_sizes = []\n",
    "   \n",
    "    # Create CUDA events for accurate GPU timing\n",
    "    # Create CUDA events for accurate GPU timing\n",
    "    start_event = torch.cuda.Event(enable_timing=True)\n",
    "    end_event = torch.cuda.Event(enable_timing=True)\n",
    "    \n",
    "   \n",
    "    # Warmup phase\n",
    "    with torch.no_grad():\n",
    "        for i, (images, *_) in enumerate(loader):\n",
    "            if i >= warmup_batches:\n",
    "                break\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            _ = model(images)\n",
    "   \n",
    "    # Measurement phase\n",
    "    with torch.no_grad():\n",
    "        for i, (images, *_) in enumerate(loader):\n",
    "            if i >= num_batches:\n",
    "                break\n",
    "               \n",
    "            # Move data to device asynchronously\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            \n",
    "            torch.cuda.synchronize()\n",
    "            start_event.record()\n",
    "           \n",
    "            # Run inference\n",
    "            _ = model(images)\n",
    "           \n",
    "\n",
    "            end_event.record()\n",
    "            end_event.synchronize()\n",
    "            latency = start_event.elapsed_time(end_event)\n",
    "\n",
    "           \n",
    "            latencies.append(latency)\n",
    "            batch_sizes.append(images.size(0))\n",
    "   \n",
    "    # Convert to numpy for statistics\n",
    "    latencies = np.array(latencies)\n",
    "    batch_sizes = np.array(batch_sizes)\n",
    "    per_image_latencies = latencies / batch_sizes\n",
    "   \n",
    "    # Calculate statistics\n",
    "    stats = {\n",
    "        'mean_latency_ms_per_batch': float(np.mean(latencies)),\n",
    "        'std_latency_ms_per_batch': float(np.std(latencies)),\n",
    "        'mean_latency_ms_per_image': float(np.mean(per_image_latencies)),\n",
    "        'std_latency_ms_per_image': float(np.std(per_image_latencies)),\n",
    "        'throughput_imgs_per_sec': float(np.mean(batch_sizes / (latencies / 1000))),\n",
    "    }\n",
    "   \n",
    "    # Add percentiles\n",
    "    for p in percentiles:\n",
    "        stats[f'p{p}_latency_ms_per_batch'] = float(np.percentile(latencies, p))\n",
    "        stats[f'p{p}_latency_ms_per_image'] = float(np.percentile(per_image_latencies, p))\n",
    "   \n",
    "    return stats\n",
    "\n",
    "def run_latency_test(model, test_dl, device, num_batches=20, runs=5, output_csv=\"latency_results.csv\"):\n",
    "    \"\"\"Run multiple latency tests, aggregate results, and save them to a CSV file.\"\"\"\n",
    "    all_stats = defaultdict(list)\n",
    "\n",
    "    for run in range(runs):\n",
    "        print(f\"\\nRun {run + 1}/{runs}\")\n",
    "        stats = calculate_true_latency(test_dl, model, device, num_batches=num_batches)\n",
    "\n",
    "        for key, value in stats.items():\n",
    "            all_stats[key].append(value)\n",
    "\n",
    "    # Calculate aggregate statistics\n",
    "    aggregate_stats = {\n",
    "        key: {\n",
    "            'mean': float(np.mean(values)),\n",
    "            'std': float(np.std(values))\n",
    "        }\n",
    "        for key, values in all_stats.items()\n",
    "    }\n",
    "\n",
    "    print(\"\\n=== Aggregate Results ===\")\n",
    "    print(f\"Runs: {runs}\")\n",
    "    print(f\"Mean per-image latency: {aggregate_stats['mean_latency_ms_per_image']['mean']:.4f} ms ± {aggregate_stats['mean_latency_ms_per_image']['std']:.4f} ms\")\n",
    "    print(f\"Mean per-batch latency: {aggregate_stats['mean_latency_ms_per_batch']['mean']:.4f} ms ± {aggregate_stats['mean_latency_ms_per_batch']['std']:.4f} ms\")\n",
    "    print(f\"Mean throughput: {aggregate_stats['throughput_imgs_per_sec']['mean']:.2f} imgs/sec ± {aggregate_stats['throughput_imgs_per_sec']['std']:.2f}\")\n",
    "\n",
    "    # Save results to a CSV file\n",
    "    csv_exists = os.path.exists(output_csv)\n",
    "    with open(output_csv, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Write the header only if the file is newly created\n",
    "        if not csv_exists:\n",
    "            writer.writerow([\n",
    "                \"Batch Size\",\n",
    "                \"Mean Latency per Image (ms)\", \"Std Latency per Image (ms)\",\n",
    "                \"Mean Latency per Batch (ms)\", \"Std Latency per Batch (ms)\",\n",
    "                \"Mean Throughput (imgs/sec)\", \"Std Throughput (imgs/sec)\"\n",
    "            ])\n",
    "\n",
    "        # Write the row for the current batch size\n",
    "        writer.writerow([\n",
    "            test_dl.batch_size,\n",
    "            aggregate_stats['mean_latency_ms_per_image']['mean'],\n",
    "            aggregate_stats['mean_latency_ms_per_image']['std'],\n",
    "            aggregate_stats['mean_latency_ms_per_batch']['mean'],\n",
    "            aggregate_stats['mean_latency_ms_per_batch']['std'],\n",
    "            aggregate_stats['throughput_imgs_per_sec']['mean'],\n",
    "            aggregate_stats['throughput_imgs_per_sec']['std'],\n",
    "        ])\n",
    "\n",
    "    return aggregate_stats\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "batch_sizes = [2**i for i in range(0, 20)]  # Powers of 2 from 1 to 1024\n",
    "output_csv = \"latency_results_teacher_final.csv\"\n",
    "\n",
    "# Remove the CSV file if it already exists (optional, for fresh runs)\n",
    "if os.path.exists(output_csv):\n",
    "    os.remove(output_csv)\n",
    "\n",
    "print(\"\\n=== Batch Size Latency and Throughput Testing ===\")\n",
    "\n",
    "# Loop through each batch size and test latency\n",
    "for batch_size in batch_sizes:\n",
    "    print(f\"\\nTesting with batch size: {batch_size}\")\n",
    "    train_dl, val_dl, test_dl = get_dataloaders(train_ds, test_ds, batch_size=batch_size, num_workers=4)\n",
    "    \n",
    "    run_latency_test(model, test_dl, device, num_batches=100, runs=5, output_csv=output_csv)\n",
    "\n",
    "print(f\"\\nResults saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data into a pandas DataFrame\n",
    "csv_file = \"latency_results_teacher_final.csv\"  # Replace with your CSV file name\n",
    "data = pd.read_csv(csv_file)\n",
    "\n",
    "# Plot Mean Latency Per Image and Per Batch\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot mean latency per image\n",
    "plt.errorbar(\n",
    "    data[\"Batch Size\"],\n",
    "    data[\"Mean Latency per Image (ms)\"],\n",
    "    yerr=data[\"Std Latency per Image (ms)\"],\n",
    "    fmt='o-',\n",
    "    label=\"Mean Latency per Image (ms)\",\n",
    "    capsize=5\n",
    ")\n",
    "\n",
    "# Plot mean latency per batch\n",
    "# plt.errorbar(\n",
    "#     data[\"Batch Size\"],\n",
    "#     data[\"Mean Latency per Batch (ms)\"],\n",
    "#     yerr=data[\"Std Latency per Batch (ms)\"],\n",
    "#     fmt='s-',\n",
    "#     label=\"Mean Latency per Batch (ms)\",\n",
    "#     capsize=5\n",
    "# )\n",
    "\n",
    "# Set log scale for x-axis\n",
    "plt.xscale(\"log\", base=2)\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel(\"Batch Size (log scale)\")\n",
    "plt.ylabel(\"Latency (ms)\")\n",
    "plt.title(\"Mean Latency Per Image and Per Batch Across Batch Sizes\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plot Throughput with Error Bars\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(data[\"Batch Size\"], data[\"Mean Throughput (imgs/sec)\"], yerr=data[\"Std Throughput (imgs/sec)\"],\n",
    "             fmt='^-', label=\"Throughput\", capsize=5, color='green')\n",
    "plt.xscale(\"log\", base=2)  # Log scale for batch sizes\n",
    "plt.xlabel(\"Batch Size (log scale)\")\n",
    "plt.ylabel(\"Throughput (images/sec)\")\n",
    "plt.title(\"Model Throughput Across Batch Sizes\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvsb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
